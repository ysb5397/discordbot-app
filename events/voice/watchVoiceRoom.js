const { Events, ChannelType } = require('discord.js');
const { joinVoiceChannel, getVoiceConnection, EndBehaviorType, createAudioPlayer, createAudioResource } = require('@discordjs/voice');
const prism = require('prism-media');
const speech = require('@google-cloud/speech');
const { GoogleGenerativeAI } = require('@google/generative-ai');
const textToSpeech = require('@google-cloud/text-to-speech');
const { Readable } = require('stream');

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash" });
const credentials = JSON.parse(process.env.DISCORD_CREDENTIALS_JSON);
const speechClient = new speech.SpeechClient({ credentials });
const ttsClient = new textToSpeech.TextToSpeechClient({ credentials });

const TARGET_CHANNEL_ID = "1353292092016693282";
let isListening = false;

// STT ì„¤ì •
const sttRequest = {
    config: {
        encoding: 'LINEAR16',
        sampleRateHertz: 48000,
        languageCode: 'ko-KR',
    },
    interimResults: false,
};

function startListening(connection) {
    console.log("ìŒì„± ë“£ê¸° ì‹œì‘!");
    connection.receiver.speaking.on('start', (userId) => {
        if (isListening) return;
        isListening = true;
        console.log(`${userId} ë‹˜ì´ ë§ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤.`);

        const audioStream = connection.receiver.subscribe(userId, {
            end: {
                behavior: EndBehaviorType.AfterSilence,
                duration: 1000,
            },
        });

        const recognizeStream = speechClient
            .streamingRecognize(sttRequest)
            .on('error', (error) => {
                console.error('STT ìŠ¤íŠ¸ë¦¼ ì˜¤ë¥˜:', error);
                isListening = false;
            })
            .on('data', async (data) => {
                const transcript = data.results[0]?.alternatives[0]?.transcript;
                if (transcript) {
                    console.log(`[STT ê²°ê³¼] ${transcript}`);
                    recognizeStream.destroy();

                    try {
                        const systemInstruction = "ë„ˆëŠ” ìŒì„±ìœ¼ë¡œ ëŒ€í™”í•˜ëŠ” AI ë¹„ì„œì•¼. ë‹µë³€ì€ í•­ìƒ ë§ˆí¬ë‹¤ìš´ì´ë‚˜ íŠ¹ìˆ˜ê¸°í˜¸ ì—†ì´, ì‹¤ì œ ëŒ€í™”ì²˜ëŸ¼ ìœ ì—°í•˜ê²Œ í•´ì¤˜.";
                        const result = await model.generateContent([systemInstruction, transcript]);
                        const response = await result.response;
                        const text = response.text();
                        console.log(`[Gemini ë‹µë³€] ${text}`);

                        const [ttsResponse] = await ttsClient.synthesizeSpeech({
                            input: { text: text },
                            voice: { languageCode: 'ko-KR', name: 'ko-KR-Chirp3-HD-Sulafat' },
                            audioConfig: { audioEncoding: 'MP3' },
                        });

                        const audioBuffer = ttsResponse.audioContent;
                        const ttsStream = new Readable({
                            read() {
                                this.push(audioBuffer);
								this.push(null);
                            }
                        });

                        const player = createAudioPlayer();
                        const resource = createAudioResource(ttsStream);
                        
                        connection.subscribe(player);
                        player.play(resource);

                        player.on('idle', () => {
                            console.log('TTS ì¬ìƒ ì™„ë£Œ. ë‹¤ì‹œ ë“¤ì„ ì¤€ë¹„ ì™„ë£Œ.');
                            isListening = false;
                        });

                    } catch (error) {
                        console.error('Gemini/TTS ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:', error);
                        isListening = false;
                    }
                }
            });

        const pcmStream = new prism.opus.Decoder({ frameSize: 960, channels: 1, rate: 48000 });
        audioStream.pipe(pcmStream).pipe(recognizeStream);

        audioStream.on('end', () => {
            console.log('ì‚¬ìš©ì ìŒì„± ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ.');
        });
    });
}


module.exports = {
    name: Events.VoiceStateUpdate,
    async execute(oldState, newState) {
        if (newState.member.user.bot) return;

        const client = newState.client;
        const targetChannel = await client.channels.fetch(TARGET_CHANNEL_ID).catch(() => null);
        if (!targetChannel || targetChannel.type !== ChannelType.GuildVoice) {
            console.log(`IDê°€ ${TARGET_CHANNEL_ID}ì¸ ìŒì„± ì±„ë„ì„ ì°¾ì„ ìˆ˜ ì—†ì–´. IDë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì¤˜!`);
            return;
        }

        // ì‚¬ìš©ìê°€ ì§€ì •ëœ ì±„ë„ì— ë“¤ì–´ì™”ì„ ë•Œ
        if (oldState.channelId !== TARGET_CHANNEL_ID && newState.channelId === TARGET_CHANNEL_ID) {
            let connection = getVoiceConnection(newState.guild.id);
            if (!connection) {
                console.log(`'${newState.member.displayName}'ë‹˜ì´ '${targetChannel.name}' ì±„ë„ì— ë“¤ì–´ì™€ì„œ ë‚˜ë„ ì ‘ì†í• ê²Œ!`);
                connection = joinVoiceChannel({
                    channelId: targetChannel.id,
                    guildId: targetChannel.guild.id,
                    adapterCreator: targetChannel.guild.voiceAdapterCreator,
                    selfDeaf: false,
                });
                
                // ë´‡ì´ ì±„ë„ì— ì ‘ì†í•˜ë©´ ë°”ë¡œ ë¦¬ìŠ¤ë‹ ì‹œì‘
                startListening(connection);
            }
        }
        // ì‚¬ìš©ìê°€ ì§€ì •ëœ ì±„ë„ì—ì„œ ë‚˜ê°”ì„ ë•Œ
        else if (oldState.channelId === TARGET_CHANNEL_ID && newState.channelId !== TARGET_CHANNEL_ID) {
            // ì±„ë„ì— ë´‡ ì™¸ì— ë‹¤ë¥¸ ì‚¬ìš©ìê°€ ì•„ë¬´ë„ ì—†ëŠ”ì§€ í™•ì¸
            const humanMembers = oldState.channel.members.filter(member => !member.user.bot);
            if (humanMembers.size === 0) {
                const connection = getVoiceConnection(oldState.guild.id);
                if (connection) {
                    console.log(`'${targetChannel.name}' ì±„ë„ì— ì•„ë¬´ë„ ì—†ì–´ì„œ ë‚˜ê°ˆê²Œ... ğŸ˜¢`);
                    connection.destroy();
                }
            }
        }
    },
};
