const { Events, SpeakingMap } = require('discord.js');
const { getVoiceConnection, EndBehaviorType, createAudioPlayer, createAudioResource, NoSubscriberBehavior, AudioPlayerStatus } = require('@discordjs/voice');
const prism = require('prism-media');
const speech = require('@google-cloud/speech');
const { GoogleGenerativeAI } = require('@google/generative-ai');
const textToSpeech = require('@google-cloud/text-to-speech');
const { Readable } = require('stream');

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });
const credentials = JSON.parse(process.env.DISCORD_CREDENTIALS_JSON);
const speechClient = new speech.SpeechClient({ credentials });
const ttsClient = new textToSpeech.TextToSpeechClient({ credentials });

let isListening = false;

module.exports = {
    name: Events.MessageCreate,
    async execute(message) {
        if (message.author.bot || message.content !== '!ì°¸ê°€') return;

        const member = message.member;
        if (!member?.voice.channel) {
            return message.reply('ìŒì„± ì±„ë„ì— ë¨¼ì € ë“¤ì–´ê°€ ìˆì–´ì•¼ í•´! ğŸ˜¥');
        }

        const channel = member.voice.channel;
        const connection = joinVoiceChannel({
            channelId: channel.id,
            guildId: channel.guild.id,
            adapterCreator: channel.guild.voiceAdapterCreator,
            selfDeaf: false,
        });

        message.reply(`'${channel.name}' ì±„ë„ì— ì°¸ê°€í–ˆì–´. ì´ì œë¶€í„°ëŠ” ë§ë§Œ í•˜ë©´ ë‚´ê°€ ë“¤ì„ê²Œ! ğŸ¤«`);

        connection.receiver.speaking.on('start', (userId) => {
            if (isListening) return;
            isListening = true;

            console.log(`${userId} ë‹˜ì´ ë§ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤. STT ìŠ¤íŠ¸ë¦¼ì„ ì—½ë‹ˆë‹¤.`);
            
            const recognizeStream = speechClient.streamingRecognize({
                config: {
                    encoding: 'LINEAR16',
                    sampleRateHertz: 48000,
                    languageCode: 'ko-KR',
                },
                interimResults: false,
            })
            .on('error', (err) => {
                console.error('STT ìŠ¤íŠ¸ë¦¼ ì˜¤ë¥˜:', err);
                isListening = false;
            })
            .on('data', async data => {
                const transcript = data.results[0]?.alternatives[0]?.transcript;
                if (transcript) {
                    console.log(`[STT ê²°ê³¼] ${transcript}`);
                    
                    try {
                        const systemInstruction = "ë„ˆëŠ” ìŒì„±ìœ¼ë¡œ ëŒ€í™”í•˜ëŠ” AI ë¹„ì„œì•¼. ë‹µë³€ì€ í•­ìƒ ë§ˆí¬ë‹¤ìš´ì´ë‚˜ íŠ¹ìˆ˜ê¸°í˜¸ ì—†ì´, ì‹¤ì œ ëŒ€í™”ì²˜ëŸ¼ í•´ì¤˜.";
                        const result = await model.generateContent([systemInstruction, transcript]);
                        const response = await result.response;
                        const text = response.text();
                        console.log(`[Gemini ë‹µë³€] ${text}`);

                        const [ttsResponse] = await ttsClient.synthesizeSpeech({
                            input: { text: text },
                            voice: {
                                languageCode: 'ko-KR',
                                name: 'ko-KR-Chirp3-HD-Sulafat'
                            },
                            audioConfig: { audioEncoding: 'MP3' },
                        });

                        const audioBuffer = ttsResponse.audioContent;
                        const ttsAudioStream = new Readable({
                            read() {
                                this.push(audioBuffer);
                                this.push(null);
                            }
                        });
                        const audioResource = createAudioResource(ttsAudioStream);
                        const player = createAudioPlayer();

                        connection.subscribe(player);
                        player.play(audioResource);

                        player.on(AudioPlayerStatus.Idle, () => {
                            console.log('ëŒ€ë‹µì´ ëë‚¬ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë“¤ì„ ì¤€ë¹„ ì™„ë£Œ.');
                            isListening = false;
                        });

                    } catch (error) {
                        console.error("ìµœì¢… ë‹¨ê³„ì—ì„œ ì˜¤ë¥˜ ë°œìƒ:", error);
                        isListening = false;
                    }
                }
            });

            const audioStream = connection.receiver.subscribe(userId, {
                end: {
                    behavior: EndBehaviorType.AfterSilence,
                    duration: 1500,
                },
            });
            
            const pcmStream = new prism.opus.Decoder({ frameSize: 960, channels: 1, rate: 48000 });
            audioStream.pipe(pcmStream).pipe(recognizeStream);
        });
    },
};