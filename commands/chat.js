// íŒŒì¼ ìœ„ì¹˜: /commands/chat.js

const { SlashCommandBuilder, InteractionContextType } = require('discord.js');
const { Interaction } = require('../utils/database.js');
const { getChatResponseStreamOrFallback, getEmbedding } = require('../utils/ai_helper.js');
const { logToDiscord } = require('../utils/catch_log.js');
const { createAiResponseEmbed } = require('../utils/embed_builder.js');

/**
 * ìœ ì‚¬í•œ ê¸°ì–µì„ ê²€ìƒ‰í•˜ì—¬ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€í•  í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
 */
async function retrieveMemories(query, userId) {
    try {
        const queryVector = await getEmbedding(query);
        if (!queryVector) return "";

        const results = await Interaction.aggregate([
            {
                "$vectorSearch": {
                    "index": "default",
                    "path": "embedding",
                    "queryVector": queryVector,
                    "numCandidates": 50, // í›„ë³´êµ° 50ê°œ ê²€ìƒ‰
                    "limit": 3,          // ìƒìœ„ 3ê°œë§Œ ì„ íƒ
                    "filter": {
                        "userId": { "$eq": userId } // ë‚´ ê¸°ì–µë§Œ ê²€ìƒ‰
                    }
                }
            },
            {
                "$project": {
                    "content": 1,
                    "botResponse": 1,
                    "score": { "$meta": "vectorSearchScore" }
                }
            },
            {
                "$match": {
                    "score": { "$gte": 0.75 } // ìœ ì‚¬ë„ 0.75 ì´ìƒë§Œ ì‚¬ìš© (ì—„ê²©í•˜ê²Œ)
                }
            }
        ]);

        if (results.length === 0) return "";

        console.log(`[Memory RAG] '${userId}'ë‹˜ì˜ ì§ˆë¬¸ì— ëŒ€í•´ ${results.length}ê°œì˜ ê´€ë ¨ ê¸°ì–µì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.`);

        // ê¸°ì–µ í¬ë§·íŒ…
        const memoryContext = results.map((doc, i) =>
            `[ê¸°ì–µ ${i + 1}] (ìœ ì‚¬ë„: ${(doc.score * 100).toFixed(0)}%)\nì‚¬ìš©ì: ${doc.content}\nAI: ${doc.botResponse}`
        ).join('\n\n');

        return `\n\n[ì°¸ê³ í•  ê³¼ê±° ëŒ€í™” ê¸°ì–µ]\n${memoryContext}\n----------------\nìœ„ ê¸°ì–µì„ ì°¸ê³ í•´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€ë‹µí•´ì¤˜.\n`;

    } catch (error) {
        console.error('[Memory RAG Error]', error);
        return ""; // ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ê¸°ì–µ ì—†ì´ ì§„í–‰
    }
}

/**
 * getChatResponseStreamOrFallback ì œë„ˆë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ì²˜ë¦¬
 */
async function handleRegularConversation(interaction, startTime, selectedModel, tokenLimit) {
    const client = interaction.client;
    const userQuestion = interaction.options.getString('question');
    const sessionId = interaction.user.id;
    const attachment = interaction.options.getAttachment('file');

    let history = [];
    let promptData = { question: userQuestion };

    const memoryContext = await retrieveMemories(userQuestion, sessionId);

    if (memoryContext) {
        promptData.question = `${memoryContext}\nì‚¬ìš©ì ì§ˆë¬¸: ${userQuestion}`;
    }

    try {
        const recentInteractions = await Interaction.find({
            userId: sessionId, type: { $in: ['MESSAGE', 'MENTION'] }
        }).sort({ timestamp: -1 }).limit(10).lean();

        if (recentInteractions.length > 0) {
            history = recentInteractions.reverse().flatMap(doc => {
                const userMessage = typeof doc.content === 'string' ? doc.content : JSON.stringify(doc.content);
                const userTurn = { role: 'user', parts: [{ text: userMessage }] };

                if (doc.botResponse) {
                    return [userTurn, { role: 'model', parts: [{ text: doc.botResponse }] }];
                }
                return [];
            });
            promptData.history = history;
        }
    } catch (dbError) {
        console.error('[/chat] ëŒ€í™” ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨:', dbError);
        logToDiscord(client, 'ERROR', 'ëŒ€í™” ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨', interaction, dbError, 'handleRegularConversation_HistoryLoad');
    }

    let fullResponseText = "";
    let finalMessage = null;
    let isFallback = false;
    let finalError = null;

    let lastUpdateTime = 0;
    const updateInterval = 1800;
    let currentEmbed = null;

    const debouncedUpdate = async (isFinal = false) => {
        const now = Date.now();
        if (!isFinal && now - lastUpdateTime < updateInterval) return;
        lastUpdateTime = now;

        const duration = now - startTime;
        const isStreaming = !isFinal && !finalError;

        let description = fullResponseText.substring(0, 4090) + (isStreaming ? "..." : "");
        if (finalMessage) description += `\n\n${finalMessage}`;

        const ragInfo = memoryContext ? "ğŸ§  ê¸°ì–µ ê²€ìƒ‰ë¨" : "";

        currentEmbed = createAiResponseEmbed({
            title: userQuestion.substring(0, 250) + (userQuestion.length > 250 ? '...' : ''),
            description: description,
            duration: duration,
            user: interaction.user,
            isFallback: isFallback,
            imageUrl: attachment ? attachment.url : undefined,
            footerPrefix: `Powered by AI ${ragInfo}`
        });

        try {
            await interaction.editReply({
                content: `<@${sessionId}>${isStreaming ? ' ìƒê° ì¤‘...' : ''}`,
                embeds: [currentEmbed]
            });
        } catch (editError) {
            console.error('[/chat] ìŠ¤íŠ¸ë¦¬ë° ì¤‘ editReply ì‹¤íŒ¨:', editError);
            logToDiscord(client, 'WARN', 'ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨', interaction, editError, 'handleRegularConversation_StreamUpdate');
            finalError = editError;
        }
    };

    try {
        const stream = getChatResponseStreamOrFallback(promptData, attachment, sessionId, { client, interaction, task: 'chat' }, selectedModel, tokenLimit);

        for await (const result of stream) {
            if (result.error) {
                finalError = result.error;
                break;
            }
            if (result.textChunk) {
                fullResponseText += result.textChunk;
                await debouncedUpdate(false);
            }
            if (result.finalResponse) {
                fullResponseText = result.finalResponse.text;
                finalMessage = result.finalResponse.message;
                isFallback = result.isFallback ?? false;
                break;
            }
        }

        if (finalError) {
            throw finalError;
        } else {
            await debouncedUpdate(true);

            try {
                const contentToSave = userQuestion + (attachment ? ` (ì²¨ë¶€: ${attachment.name})` : '');

                const embedding = await getEmbedding(contentToSave);

                const finalDescription = fullResponseText + (finalMessage ? `\n\n${finalMessage}` : '');

                const successInteraction = new Interaction({
                    interactionId: interaction.id + (isFallback ? '-fallback' : ''),
                    channelId: interaction.channelId,
                    userId: sessionId,
                    userName: interaction.user.username,
                    type: 'MESSAGE',
                    content: contentToSave,
                    botResponse: finalDescription.substring(0, 4000),
                    embedding: embedding
                });
                await successInteraction.save();
            } catch (dbError) {
                console.error('[/chat] ëŒ€í™” ì €ì¥ ì‹¤íŒ¨:', dbError);
                logToDiscord(client, 'ERROR', 'ëŒ€í™” ì €ì¥ ì‹¤íŒ¨', interaction, dbError, 'handleRegularConversation_DBSave');
            }
        }

    } catch (error) {
        console.error('[/chat] ìµœì¢… ì—ëŸ¬:', error);
        throw error;
    }
}


module.exports = {
    data: new SlashCommandBuilder()
        .setName('chat')
        .setDescription('AIì™€ ëŒ€í™”í•˜ê±°ë‚˜, ì €ì¥ëœ ê¸°ì–µì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.')
        .setContexts([
            InteractionContextType.Guild,
            InteractionContextType.BotDM,
            InteractionContextType.PrivateChannel,
        ])
        .addStringOption(option =>
            option.setName('model')
                .setDescription('ì‚¬ìš©í•  AI ëª¨ë¸ì„ ì„ íƒí•©ë‹ˆë‹¤. (ê¸°ë³¸: Gemini 2.5 Flash)')
                .setRequired(true)
                .addChoices(
                    { name: 'Gemini 2.5 Flash', value: 'gemini-2.5-flash' },
                    { name: 'Gemini 2.5 Pro', value: 'gemini-2.5-pro' },
                ))
        .addStringOption(option =>
            option.setName('question')
                .setDescription('AIì—ê²Œ í•  ì§ˆë¬¸ ë˜ëŠ” ê²€ìƒ‰í•  ë‚´ìš©')
                .setRequired(true))
        .addIntegerOption(option =>
            option.setName('token_limit')
                .setDescription('AI ì‘ë‹µì˜ ìµœëŒ€ í† í° ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. (ê¸°ë³¸: 2048)')
                .setRequired(false)
                .setMinValue(0))
        .addAttachmentOption(option =>
            option.setName('file')
                .setDescription('AIì—ê²Œ ë³´ì—¬ì¤„ íŒŒì¼ì„ ì²¨ë¶€í•˜ì„¸ìš” (ì´ë¯¸ì§€, ì½”ë“œ ë“±).')
                .setRequired(false)),

    async execute(interaction) {
        const startTime = Date.now();
        await interaction.deferReply();

        const selectedModel = interaction.options.getString('model');
        const tokenLimit = interaction.options.getInteger('token_limit') || 2048;
        await handleRegularConversation(interaction, startTime, selectedModel, tokenLimit);
    },
};
